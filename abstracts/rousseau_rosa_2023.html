<html>
<body>
<p>
    <b>Bayesian nonparametric manifold learning
   </b>
    </p>
    <p>
      In high dimensions it is common to assume that the data have a lower dimensional structure.  We consider two types of low dimensional structure:  in the firstpart  the  data  is  assumed  to  be  concentrated  near  an  unknown  low  dimensionalmanifold, in the second case it is assumed to be possibly concentrated on an unknown manifold.  In both cases neither the manifold nor the density is known.  Atypical example is for noisy observations on an unknown low dimensional manifold. 
    </p>
    <p>
      We first consider a family of Bayesian nonparametric density estimators basedon location - scale Gaussian mixture priors and we study the asymptotic propertiesof the posterior distribution.  Our work shows in particular that non conjuguate location-scale  Gaussian  mixture  models  can  adapt  to  complex  geometries  andspatially varying regularity when the density is supported near a low dimensional manifold.
    </p>
    <p>
      In the second part of the talk we will consider also the case where the distribution is supported on a low dimensional manifold.  In this non dominated model,we study different types of posterior contraction rates:  Wasserstein and $L_1(\mu_\mathcal{M})$ where $\mu_\mathcal{M}$ is the Haussdorff measure on the manifold $\mathcal{M}$ supporting the density.Some more generic results on Wasserstein contraction rates are also discussed.
    </p>
    <p>
       <!-- Zoom link: TBA one day prior to the webinar -->
       Zoom link: <a href="https://ucl.zoom.us/j/91837224665"><b><font color=#0f5e9b>LINK</font></b></a>  <!-- (Passcode: XXXX)-->
    </p>
</body>
</html>
